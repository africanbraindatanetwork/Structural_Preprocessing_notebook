{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI Preprocessing Scripts 8-10\n",
    "## Complete Working Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nibabel nilearn SimpleITK scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from nilearn import datasets\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import SimpleITK as sitk\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from datetime import datetime\n",
    "from nibabel.orientations import io_orientation, axcodes2ornt, ornt_transform\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: /Users/aazeez/Documents/Personal/ABDN_2025/content5/derivatives\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "OUTPUT_DIR = Path('/Users/aazeez/Documents/Personal/ABDN_2025/content5/derivatives')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "print(f\"Output: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def reorient_img(img):\n",
    "    curr = io_orientation(img.affine)\n",
    "    targ = axcodes2ornt('RAS')\n",
    "    trans = ornt_transform(curr, targ)\n",
    "    data = nib.apply_orientation(img.get_fdata(), trans)\n",
    "    aff = img.affine @ nib.orientations.inv_ornt_aff(trans, img.shape)\n",
    "    return nib.Nifti1Image(data, aff)\n",
    "\n",
    "def correct_bias(img):\n",
    "    s = sitk.GetImageFromArray(img.get_fdata().T)\n",
    "    s = sitk.Cast(s, sitk.sitkFloat32)\n",
    "    c = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    c.SetMaximumNumberOfIterations([50,50,50,50])\n",
    "    r = c.Execute(s)\n",
    "    return nib.Nifti1Image(sitk.GetArrayFromImage(r).T, img.affine)\n",
    "\n",
    "def strip_skull(img):\n",
    "    d = img.get_fdata()\n",
    "    t = np.percentile(d[d>0], 20)\n",
    "    m = d > t\n",
    "    m = morphology.remove_small_objects(m, 1000)\n",
    "    m = ndimage.binary_fill_holes(m)\n",
    "    l, _ = ndimage.label(m)\n",
    "    s = ndimage.sum(m, l, range(l.max()+1))\n",
    "    m = l == np.argmax(s)\n",
    "    m = ndimage.binary_closing(m, iterations=3)\n",
    "    return nib.Nifti1Image(d*m, img.affine), nib.Nifti1Image(m.astype(np.uint8), img.affine)\n",
    "\n",
    "def segment_img(img, mask):\n",
    "    d = img.get_fdata()\n",
    "    md = mask.get_fdata().astype(bool)\n",
    "    v = d[md].reshape(-1, 1)\n",
    "    vn = (v - v.mean()) / v.std()\n",
    "    g = GaussianMixture(n_components=3, random_state=42)\n",
    "    g.fit(vn)\n",
    "    l = g.predict(vn)\n",
    "    s = np.zeros(d.shape, dtype=np.uint8)\n",
    "    s[md] = l + 1\n",
    "    si = np.argsort(g.means_.flatten())\n",
    "    ss = np.zeros_like(s)\n",
    "    for i, idx in enumerate(si):\n",
    "        ss[s == idx+1] = i+1\n",
    "    return nib.Nifti1Image(ss, img.affine)\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT 8: Pipeline Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline class defined\n"
     ]
    }
   ],
   "source": [
    "class StructuralPreprocessingPipeline:\n",
    "    def __init__(self, subject_id, input_file, output_dir='derivatives'):\n",
    "        self.subject_id = subject_id\n",
    "        self.input_file = input_file\n",
    "        self.output_dir = Path(output_dir) / subject_id\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def run(self):\n",
    "        try:\n",
    "            print(f\"Processing {self.subject_id}...\")\n",
    "            orig = nib.load(self.input_file)\n",
    "            reor = reorient_img(orig)\n",
    "            corr = correct_bias(reor)\n",
    "            brain, mask = strip_skull(corr)\n",
    "            seg = segment_img(brain, mask)\n",
    "            \n",
    "            nib.save(brain, self.output_dir/f'{self.subject_id}_brain.nii.gz')\n",
    "            nib.save(seg, self.output_dir/f'{self.subject_id}_seg.nii.gz')\n",
    "            \n",
    "            vv = np.prod(orig.header.get_zooms())\n",
    "            sd = seg.get_fdata()\n",
    "            vols = {t: float(np.sum(sd==l)*vv/1000) for t,l in [('CSF',1),('GM',2),('WM',3)]}\n",
    "            vols['TIV'] = sum(vols.values())\n",
    "            \n",
    "            d = brain.get_fdata()\n",
    "            md = mask.get_fdata().astype(bool)\n",
    "            snr = d[md].mean() / d[~md].std() if d[~md].std()>0 else 0\n",
    "            \n",
    "            qc = {'subject_id': self.subject_id, 'snr': float(snr), 'volumes': vols, 'timestamp': datetime.now().isoformat()}\n",
    "            with open(self.output_dir/f'{self.subject_id}_qc.json', 'w') as f:\n",
    "                json.dump(qc, f, indent=2)\n",
    "            \n",
    "            print(f\"✓ {self.subject_id} done\")\n",
    "            return {'status': 'success', 'output_dir': str(self.output_dir)}\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {self.subject_id} failed: {e}\")\n",
    "            return {'status': 'failed', 'error': str(e)}\n",
    "\n",
    "print(\"Pipeline class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT 9: Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch functions defined\n"
     ]
    }
   ],
   "source": [
    "def process_subject(info):\n",
    "    p = StructuralPreprocessingPipeline(info['subject_id'], info['input_file'])\n",
    "    return p.run()\n",
    "\n",
    "def batch_process(subjects_csv, n_jobs=2):\n",
    "    df = pd.read_csv(subjects_csv)\n",
    "    with ProcessPoolExecutor(max_workers=n_jobs) as ex:\n",
    "        results = list(ex.map(process_subject, df.to_dict('records')))\n",
    "    rdf = pd.DataFrame(results)\n",
    "    rdf.to_csv('results.csv', index=False)\n",
    "    print(f\"Success: {(rdf['status']=='success').sum()}/{len(rdf)}\")\n",
    "    return rdf\n",
    "\n",
    "print(\"Batch functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT 10: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation defined\n",
      "\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "SCRIPTS 8-10 COMPLETE\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def validate(subject_dir):\n",
    "    sd = Path(subject_dir)\n",
    "    rep = {'subject_id': sd.name, 'checks': {}, 'warnings': [], 'errors': []}\n",
    "    for r in ['_brain.nii.gz', '_seg.nii.gz', '_qc.json']:\n",
    "        if not list(sd.glob(f'*{r}')):\n",
    "            rep['errors'].append(f\"Missing {r}\")\n",
    "        else:\n",
    "            rep['checks'][r] = 'OK'\n",
    "    rep['status'] = 'FAILED' if rep['errors'] else 'PASSED'\n",
    "    return rep\n",
    "\n",
    "print(\"Validation defined\")\n",
    "print(\"\\n=\" * 10)\n",
    "print(\"SCRIPTS 8-10 COMPLETE\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
